# 激活函数

激活函数是人工神经网络模型中经常使用的函数，它的作用是给模型引入非线性因素，能够处理一些线性模型无法处理的非线性数据，从而增强模型的表达能力，提高模型的准确性。

举个例子，如果我们要训练一个模型来识别手写数字，那么如果使用的是线性模型，因为手写数字比较复杂，而线性模型处理非线性数据的能力非常弱，所以准确率会比较低。但是如果我们在模型中加入激活函数，比如常用的ReLU函数，便可以使模型对非线性数据变得更加敏感，因此可以显著提高模型的准确率。

常见的激活函数还包括Sigmoid函数、tanh函数、Softmax函数等，它们各有不同的特点和应用场景。

例如，Sigmoid函数的取值范围是(0,1)，在处理一些需要输出概率的场景，比如图像分类、语音识别等，Sigmoid函数可以用来输出每个类别出现的概率。

另外，激活函数的选择还要考虑到梯度消失和梯度爆炸等问题。因此，在实际应用中，一般需要结合模型的具体情况进行综合考虑和选择。